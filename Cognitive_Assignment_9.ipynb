{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "59b535c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer ,WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize ,sent_tokenize\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "440b8405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['technology', 'is', 'evolving', 'at', 'an', 'unprecedented', 'pace', 'shaping', 'the', 'way', 'we', 'communicate', 'learn', 'and', 'work', 'from', 'artificial', 'intelligence', 'to', 'quantum', 'computing', 'modern', 'innovations', 'are', 'transforming', 'industries', 'across', 'the', 'globe', 'smart', 'devices', 'and', 'internet', 'connectivity', 'have', 'made', 'information', 'more', 'accessible', 'than', 'ever', 'as', 'a', 'tech', 'enthusiast', 'i', 'find', 'joy', 'in', 'exploring', 'new', 'gadgets', 'software', 'tools', 'and', 'digital', 'platforms', 'staying', 'updated', 'with', 'technological', 'trends', 'not', 'only', 'fuels', 'my', 'curiosity', 'but', 'also', 'helps', 'me', 'grow', 'professionally']\n",
      "['technology is evolving at an unprecedented pace shaping the way we communicate learn and work \\nfrom artificial intelligence to quantum computing modern innovations are transforming industries across the globe \\nsmart devices and internet connectivity have made information more accessible than ever \\nas a tech enthusiast i find joy in exploring new gadgets software tools and digital platforms \\nstaying updated with technological trends not only fuels my curiosity but also helps me grow professionally']\n",
      "['technology', 'evolving', 'unprecedented', 'pace', 'shaping', 'way', 'communicate', 'learn', 'work', 'artificial', 'intelligence', 'quantum', 'computing', 'modern', 'innovations', 'transforming', 'industries', 'across', 'globe', 'smart', 'devices', 'internet', 'connectivity', 'made', 'information', 'accessible', 'ever', 'tech', 'enthusiast', 'find', 'joy', 'exploring', 'new', 'gadgets', 'software', 'tools', 'digital', 'platforms', 'staying', 'updated', 'technological', 'trends', 'fuels', 'curiosity', 'also', 'helps', 'grow', 'professionally']\n",
      "Counter({'technology': 1, 'evolving': 1, 'unprecedented': 1, 'pace': 1, 'shaping': 1, 'way': 1, 'communicate': 1, 'learn': 1, 'work': 1, 'artificial': 1, 'intelligence': 1, 'quantum': 1, 'computing': 1, 'modern': 1, 'innovations': 1, 'transforming': 1, 'industries': 1, 'across': 1, 'globe': 1, 'smart': 1, 'devices': 1, 'internet': 1, 'connectivity': 1, 'made': 1, 'information': 1, 'accessible': 1, 'ever': 1, 'tech': 1, 'enthusiast': 1, 'find': 1, 'joy': 1, 'exploring': 1, 'new': 1, 'gadgets': 1, 'software': 1, 'tools': 1, 'digital': 1, 'platforms': 1, 'staying': 1, 'updated': 1, 'technological': 1, 'trends': 1, 'fuels': 1, 'curiosity': 1, 'also': 1, 'helps': 1, 'grow': 1, 'professionally': 1})\n"
     ]
    }
   ],
   "source": [
    "paragraph = \"\"\"Technology is evolving at an unprecedented pace, shaping the way we communicate, learn, and work. \n",
    "From artificial intelligence to quantum computing, modern innovations are transforming industries across the globe. \n",
    "Smart devices and internet connectivity have made information more accessible than ever. \n",
    "As a tech enthusiast, I find joy in exploring new gadgets, software tools, and digital platforms. \n",
    "Staying updated with technological trends not only fuels my curiosity but also helps me grow professionally.\"\"\"\n",
    "\n",
    "# 1. Convert text to lowercase and remove punctuation using re. \n",
    "paragraph=paragraph.lower()\n",
    "\n",
    "for punc in string.punctuation:\n",
    "    paragraph = paragraph.replace(punc, '')\n",
    "\n",
    "# 2. Tokenize the text into words and sentences. \n",
    "words=word_tokenize(paragraph)\n",
    "sents=sent_tokenize(paragraph)\n",
    "print(words)\n",
    "print(sents)\n",
    "\n",
    "# 4. Remove stopwords (using NLTK's stopwords list). \n",
    "stops=set(stopwords.words('english'))\n",
    "\n",
    "# 5. Display word frequency distribution (excluding stopwords).\n",
    "after_stops_words=[word for word in words if word not in stops]\n",
    "print(after_stops_words)\n",
    "\n",
    "frequencies=Counter(after_stops_words)\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8701ddf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['technolog', 'evolv', 'unpreced', 'pace', 'shape', 'way', 'commun', 'learn', 'work', 'artifici', 'intellig', 'quantum', 'comput', 'modern', 'innov', 'transform', 'industri', 'across', 'globe', 'smart', 'devic', 'internet', 'connect', 'made', 'inform', 'access', 'ever', 'tech', 'enthusiast', 'find', 'joy', 'explor', 'new', 'gadget', 'softwar', 'tool', 'digit', 'platform', 'stay', 'updat', 'technolog', 'trend', 'fuel', 'curios', 'also', 'help', 'grow', 'profession']\n",
      "['technolog', 'evolv', 'unprec', 'pac', 'shap', 'way', 'commun', 'learn', 'work', 'art', 'intellig', 'quant', 'comput', 'modern', 'innov', 'transform', 'industry', 'across', 'glob', 'smart', 'dev', 'internet', 'connect', 'mad', 'inform', 'access', 'ev', 'tech', 'enthusiast', 'find', 'joy', 'expl', 'new', 'gadget', 'softw', 'tool', 'digit', 'platform', 'stay', 'upd', 'technolog', 'trend', 'fuel', 'curios', 'also', 'help', 'grow', 'profess']\n",
      "['technology', 'evolve', 'unprecedented', 'pace', 'shape', 'way', 'communicate', 'learn', 'work', 'artificial', 'intelligence', 'quantum', 'compute', 'modern', 'innovations', 'transform', 'industries', 'across', 'globe', 'smart', 'devices', 'internet', 'connectivity', 'make', 'information', 'accessible', 'ever', 'tech', 'enthusiast', 'find', 'joy', 'explore', 'new', 'gadgets', 'software', 'tool', 'digital', 'platforms', 'stay', 'update', 'technological', 'trend', 'fuel', 'curiosity', 'also', 'help', 'grow', 'professionally']\n"
     ]
    }
   ],
   "source": [
    "st=PorterStemmer()\n",
    "ls=LancasterStemmer()\n",
    "wnl=WordNetLemmatizer()\n",
    "\n",
    "\n",
    "\n",
    "# 2. Apply stemming using NLTK's PorterStemmer and LancasterStemmer.  \n",
    "porter_words=[st.stem(word) for word in after_stops_words]\n",
    "print(porter_words)\n",
    "\n",
    "lancaster_words=[ls.stem(word) for word in after_stops_words]\n",
    "print(lancaster_words)\n",
    "\n",
    "# 3. Apply lemmatization using NLTK's WordNetLemmatizer.\n",
    "wordnet_words=[wnl.lemmatize(word,'v') for word in after_stops_words]\n",
    "print(wordnet_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "16a464d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Technology', 'evolving', 'unprecedented', 'shaping', 'communicate', 'artificial', 'intelligence', 'quantum', 'computing', 'modern', 'innovations', 'transforming', 'industries', 'across', 'devices', 'internet', 'connectivity', 'information', 'accessible', 'enthusiast', 'exploring', 'gadgets', 'software', 'digital', 'platforms', 'Staying', 'updated', 'technological', 'trends', 'curiosity', 'professionally']\n",
      "[]\n",
      "['Technology', 'From', 'Smart', 'As', 'I', 'Staying']\n",
      "['Technology', 'is', 'evolving', 'at', 'an', 'unprecedented', 'pace', 'shaping', 'the', 'way', 'we', 'communicate', 'learn', 'and', 'work', 'From', 'artificial', 'intelligence', 'to', 'quantum', 'computing', 'modern', 'innovations', 'are', 'transforming', 'industries', 'across', 'the', 'globe', 'Smart', 'devices', 'and', 'internet', 'connectivity', 'have', 'made', 'information', 'more', 'accessible', 'than', 'ever', 'As', 'a', 'tech', 'enthusiast', 'I', 'find', 'joy', 'in', 'exploring', 'new', 'gadgets', 'software', 'tools', 'and', 'digital', 'platforms', 'Staying', 'updated', 'with', 'technological', 'trends', 'not', 'only', 'fuels', 'my', 'curiosity', 'but', 'also', 'helps', 'me', 'grow', 'professionally']\n",
      "['is', 'evolving', 'at', 'an', 'unprecedented', 'and', 'artificial', 'intelligence', 'innovations', 'are', 'industries', 'across', 'and', 'internet', 'information', 'accessible', 'ever', 'As', 'a', 'enthusiast', 'I', 'in', 'exploring', 'and', 'updated', 'only', 'also']\n"
     ]
    }
   ],
   "source": [
    "paragraph = \"\"\"Technology is evolving at an unprecedented pace, shaping the way we communicate, learn, and work. \n",
    "From artificial intelligence to quantum computing, modern innovations are transforming industries across the globe. \n",
    "Smart devices and internet connectivity have made information more accessible than ever. \n",
    "As a tech enthusiast, I find joy in exploring new gadgets, software tools, and digital platforms. \n",
    "Staying updated with technological trends not only fuels my curiosity but also helps me grow professionally.\"\"\"\n",
    "\n",
    "# a. Extract all words with more than 5 letters.\n",
    "\n",
    "more_than_five=re.findall(r'\\b[a-zA-Z]{6,}\\b',paragraph)\n",
    "print(more_than_five)\n",
    "\n",
    "# b. Extract all numbers (if any exist in their text). \n",
    "\n",
    "all_nums=re.findall(r'\\b\\d+\\b',paragraph)\n",
    "print(all_nums)\n",
    "\n",
    "# c. Extract all capitalized words. \n",
    "\n",
    "capitalized_words=re.findall(r'[A-Z][a-zA-Z]*\\b',paragraph)\n",
    "print(capitalized_words)\n",
    "\n",
    "# a. Split the text into words containing only alphabets (removing digits and special\n",
    "# characters).\n",
    "only_alphas=re.findall(r'\\b[a-zA-Z]+\\b',paragraph)\n",
    "print(only_alphas)\n",
    "\n",
    "# b. Extract words starting with a vowel.\n",
    "only_vowels=re.findall(r'\\b[aeiouAEIOU][a-zA-Z]*\\b',paragraph)\n",
    "print(only_vowels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5eee32a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Technology', 'is', 'evolving', 'at', 'an', 'unprecedented', 'pace', 'shaping', 'the', 'way', 'we', 'communicate', 'learn', 'and', 'work', 'From', 'artificial', 'intelligence', 'to', 'quantum', 'computing', 'modern', 'innovations', 'are', 'transforming', 'industries', 'across', 'the', 'globe', 'Smart', 'devices', 'and', 'internet', 'connectivity', 'have', 'made', 'information', 'more', 'accessible', 'than', 'ever', 'As', 'a', 'tech', 'enthusiast', 'I', 'find', 'joy', 'in', 'exploring', 'new', 'gadgets', 'software', 'tools', 'and', 'digital', 'platforms', 'Staying', 'updated', 'with', 'technological', 'trends', 'not', 'only', 'fuels', 'my', 'curiosity', 'but', 'also', 'helps', 'me', 'grow', 'professionally']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "paragraph = \"\"\"Technology is evolving at an unprecedented pace, shaping the way we communicate, learn, and work. \n",
    "From artificial intelligence to quantum computing, modern innovations are transforming industries across the globe. \n",
    "Smart devices and internet connectivity have made information more accessible than ever. \n",
    "As a tech enthusiast, I find joy in exploring new gadgets, software tools, and digital platforms. \n",
    "Staying updated with technological trends not only fuels my curiosity but also helps me grow professionally.\"\"\"\n",
    "\n",
    "\n",
    "# 2. Write a custom tokenization function :\n",
    "def custom_tokenize(text):\n",
    "    pattern=r\"\\b(?:\\d\\.\\d+|\\d+|[a-zA-Z]+(?:'[a-zA-Z]+)?|[a-zA-Z]+(?:-[a-zA-Z]+)+)\"\n",
    "    return re.findall(pattern, text)\n",
    "\n",
    "tokens=custom_tokenize(paragraph)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9aa5d059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You can contact me at <EMAIL> or visit https://www.example.com for more info.\n",
      "Alternatively, email <EMAIL> or check http://help.company.org/docs.\n",
      "Call us at 123-456-7890 or +91 9876543210 or 7888883423  for assistance.\n",
      "\n",
      "\n",
      "You can contact me at <EMAIL> or visit <URL> for more info.\n",
      "Alternatively, email <EMAIL> or check <URL>\n",
      "Call us at 123-456-7890 or +91 9876543210 or 7888883423  for assistance.\n",
      "\n",
      "\n",
      "You can contact me at <EMAIL> or visit <URL> for more info.\n",
      "Alternatively, email <EMAIL> or check <URL>\n",
      "Call us at <PHONE> or <PHONE> or <PHONE>  for assistance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "sample_text = \"\"\"\n",
    "You can contact me at john.doe@example.com or visit https://www.example.com for more info.\n",
    "Alternatively, email support123@company.org or check http://help.company.org/docs.\n",
    "Call us at 123-456-7890 or +91 9876543210 or 7888883423  for assistance.\n",
    "\"\"\"\n",
    "\n",
    "# a. Replace email addresses with '<EMAIL>' placeholder. \n",
    "\n",
    "text_with_email_replaced=re.sub(r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b','<EMAIL>',sample_text)\n",
    "print(text_with_email_replaced)\n",
    "\n",
    "# b. Replace URLs with '<URL>' placeholder. \n",
    "\n",
    "text_with_url_replaced=re.sub(r'https?://[^\\s]+','<URL>',text_with_email_replaced)\n",
    "print(text_with_url_replaced)\n",
    "\n",
    "# c. Replace phone numbers (formats: 123-456-7890 or +91 9876543210) with\n",
    "# '<PHONE>' placeholder. \n",
    "\n",
    "text_with_phones_replaces=re.sub(r'(\\+91\\s\\d{10})|(\\d{3}-\\d{3}-\\d{4})|(\\d{10})','<PHONE>',text_with_url_replaced)\n",
    "print(text_with_phones_replaces)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
